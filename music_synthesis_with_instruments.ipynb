{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733924113683,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "vFAzh2-wnqv3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from diffusers import AudioLDM2Pipeline\n",
    "from diffusers.pipelines.pipeline_utils import AudioPipelineOutput\n",
    "from diffusers.schedulers.scheduling_ddim import DDIMSchedulerOutput\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "import scipy\n",
    "import gc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "7ca231a1bc214fb0baa71ad5a2c04692",
      "d30f403e52004129a14d09bcfd1c7b61",
      "7918654a481e4f1ba967c4f8cae3c9d3",
      "6d9e0c1165f047c4bff2a203e0f3021a",
      "cbfabbc7000e4b6cb4908312366c892d",
      "7d65956ac0c9404b88c76761653f0269",
      "20f44fdadb3844fe833a9873959d9a4a",
      "35bcdd1d2e894c63ac5afa4842481835",
      "7e011bdb5b404070b5f6888573a96c4b",
      "1dcee4440d0f4842a53332030b5206f9",
      "b4495dea30704bd68c231ca2739e336c"
     ]
    },
    "executionInfo": {
     "elapsed": 4234,
     "status": "ok",
     "timestamp": 1733924117911,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "Dyq8aAzEnqv4",
    "outputId": "c9112daa-3fbf-4601-bbf5-d981daf2f6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca231a1bc214fb0baa71ad5a2c04692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repo_id = \"cvssp/audioldm2-music\"\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "#device = xm.xla_device()\n",
    "print(f'device: {device}')\n",
    "\n",
    "pipeline = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733924117911,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "sjUcEyHQnqv5"
   },
   "outputs": [],
   "source": [
    "def custum_step_DDIM(ddim_scheduler, unet_output_epsilon, timestep, sample, X_0, reference_guidance_strength = 0.5, eta = 0.0):\n",
    "    prev_timestep = timestep - ddim_scheduler.config.num_train_timesteps // ddim_scheduler.num_inference_steps\n",
    "    alpha_prod_t = ddim_scheduler.alphas_cumprod[timestep]\n",
    "    alpha_prod_t_prev = ddim_scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else ddim_scheduler.final_alpha_cumprod\n",
    "    beta_prod_t = 1 - alpha_prod_t\n",
    "    pred_original_sample = (sample - beta_prod_t ** (0.5) * unet_output_epsilon) / alpha_prod_t ** (0.5)\n",
    "    real_original_sample = X_0 / alpha_prod_t ** (0.5)\n",
    "    pred_epsilon = unet_output_epsilon\n",
    "    variance = ddim_scheduler._get_variance(timestep, prev_timestep)\n",
    "    std_dev_t = eta * variance ** (0.5)\n",
    "    pred_sample_direction = (1 - alpha_prod_t_prev - std_dev_t**2) ** (0.5) * pred_epsilon\n",
    "\n",
    "    #TODO: 원래 pred_original_sample가 있던 자리에 (pred_original_sample*(1-reference_guidance_strength) + real_original_sample*reference_guidance_strength) 삽입\n",
    "    prev_sample = alpha_prod_t_prev ** (0.5) * (pred_original_sample*(1-reference_guidance_strength) + real_original_sample*reference_guidance_strength) + pred_sample_direction\n",
    "\n",
    "    return DDIMSchedulerOutput(prev_sample=prev_sample, pred_original_sample=pred_original_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733924117911,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "fvF7qPFrnqv5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def inference_pipe(\n",
    "        pipeline,\n",
    "        reference_latent_X_0,\n",
    "        reference_guidance_decay = None,\n",
    "        prompt: Union[str, List[str]] = None,\n",
    "        transcription: Union[str, List[str]] = None,\n",
    "        audio_length_in_s: Optional[float] = None,\n",
    "        num_inference_steps: int = 200,\n",
    "        guidance_scale: float = 0.8,\n",
    "        negative_prompt: Optional[Union[str, List[str]]] = None,\n",
    "        num_waveforms_per_prompt: Optional[int] = 1,\n",
    "        eta: float = 0.0,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        latents: Optional[torch.Tensor] = None,\n",
    "        prompt_embeds: Optional[torch.Tensor] = None,\n",
    "        negative_prompt_embeds: Optional[torch.Tensor] = None,\n",
    "        generated_prompt_embeds: Optional[torch.Tensor] = None,\n",
    "        negative_generated_prompt_embeds: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.LongTensor] = None,\n",
    "        negative_attention_mask: Optional[torch.LongTensor] = None,\n",
    "        max_new_tokens: Optional[int] = None,\n",
    "        return_dict: bool = True,\n",
    "        callback: Optional[Callable[[int, int, torch.Tensor], None]] = None,\n",
    "        callback_steps: Optional[int] = 1,\n",
    "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        output_type: Optional[str] = \"np\",\n",
    "    ):\n",
    " # 0. Convert audio input length from seconds to spectrogram height\n",
    "        vocoder_upsample_factor = np.prod(pipeline.vocoder.config.upsample_rates) / pipeline.vocoder.config.sampling_rate\n",
    "\n",
    "        if audio_length_in_s is None:\n",
    "            audio_length_in_s = pipeline.unet.config.sample_size * pipeline.vae_scale_factor * vocoder_upsample_factor\n",
    "\n",
    "        height = int(audio_length_in_s / vocoder_upsample_factor)\n",
    "\n",
    "        original_waveform_length = int(audio_length_in_s * pipeline.vocoder.config.sampling_rate)\n",
    "        if height % pipeline.vae_scale_factor != 0:\n",
    "            height = int(np.ceil(height / pipeline.vae_scale_factor)) * pipeline.vae_scale_factor\n",
    "\n",
    "        # 1. Check inputs. Raise error if not correct\n",
    "        pipeline.check_inputs(\n",
    "            prompt,\n",
    "            audio_length_in_s,\n",
    "            vocoder_upsample_factor,\n",
    "            callback_steps,\n",
    "            transcription,\n",
    "            negative_prompt,\n",
    "            prompt_embeds,\n",
    "            negative_prompt_embeds,\n",
    "            generated_prompt_embeds,\n",
    "            negative_generated_prompt_embeds,\n",
    "            attention_mask,\n",
    "            negative_attention_mask,\n",
    "        )\n",
    "\n",
    "        # 2. Define call parameters\n",
    "        if prompt is not None and isinstance(prompt, str):\n",
    "            batch_size = 1\n",
    "        elif prompt is not None and isinstance(prompt, list):\n",
    "            batch_size = len(prompt)\n",
    "        else:\n",
    "            batch_size = prompt_embeds.shape[0]\n",
    "\n",
    "        device = pipeline._execution_device\n",
    "        print(f'device:{device}')\n",
    "        # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)\n",
    "        # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`\n",
    "        # corresponds to doing no classifier free guidance.\n",
    "\n",
    "        #do_classifier_free_guidance = guidance_scale > 1.0\n",
    "        do_classifier_free_guidance = negative_prompt is not None or negative_generated_prompt_embeds is not None or negative_prompt_embeds is not None\n",
    "\n",
    "        # 3. Encode input prompt\n",
    "        prompt_embeds, attention_mask, generated_prompt_embeds = pipeline.encode_prompt(\n",
    "            prompt,\n",
    "            device,\n",
    "            num_waveforms_per_prompt,\n",
    "            do_classifier_free_guidance,\n",
    "            transcription,\n",
    "            negative_prompt,\n",
    "            prompt_embeds=prompt_embeds,\n",
    "            negative_prompt_embeds=negative_prompt_embeds,\n",
    "            generated_prompt_embeds=generated_prompt_embeds,\n",
    "            negative_generated_prompt_embeds=negative_generated_prompt_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            negative_attention_mask=negative_attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "\n",
    "        # 4. Prepare timesteps\n",
    "        pipeline.scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "        timesteps = pipeline.scheduler.timesteps\n",
    "\n",
    "        # 5. Prepare latent variables\n",
    "        num_channels_latents = pipeline.unet.config.in_channels\n",
    "        latents = pipeline.prepare_latents(\n",
    "            batch_size * num_waveforms_per_prompt,\n",
    "            num_channels_latents,\n",
    "            height,\n",
    "            prompt_embeds.dtype,\n",
    "            device,\n",
    "            generator,\n",
    "            latents,\n",
    "        )\n",
    "\n",
    "        # 6. Prepare extra step kwargs\n",
    "        extra_step_kwargs = pipeline.prepare_extra_step_kwargs(generator, eta)\n",
    "\n",
    "        # 7. Denoising loop\n",
    "        num_warmup_steps = len(timesteps) - num_inference_steps * pipeline.scheduler.order\n",
    "        with pipeline.progress_bar(total=num_inference_steps) as progress_bar:\n",
    "\n",
    "            # TODO: reference_guidance strength decay exponentially as reverse process proceeding\n",
    "            exp_reference_guidance_decay = torch.zeros_like(timesteps)\n",
    "            if reference_guidance_decay is not None:\n",
    "                step_size = pipeline.scheduler.config.num_train_timesteps / len(timesteps)\n",
    "                decay_rate_for_one_step = torch.pow(torch.tensor(reference_guidance_decay), step_size)\n",
    "                exp_reference_guidance_decay =  decay_rate_for_one_step** torch.arange(1, len(timesteps)+1)\n",
    "\n",
    "\n",
    "            for i, t in enumerate(timesteps):\n",
    "                # expand the latents if we are doing classifier free guidance\n",
    "                latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
    "                latent_model_input = pipeline.scheduler.scale_model_input(latent_model_input, t)\n",
    "\n",
    "                # predict the noise residual\n",
    "                noise_pred = pipeline.unet(\n",
    "                    latent_model_input,\n",
    "                    t,\n",
    "                    encoder_hidden_states=generated_prompt_embeds,\n",
    "                    encoder_hidden_states_1=prompt_embeds,\n",
    "                    encoder_attention_mask_1=attention_mask,\n",
    "                    return_dict=False,\n",
    "                )[0]\n",
    "\n",
    "                # perform guidance\n",
    "                if do_classifier_free_guidance:\n",
    "                    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "                    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "                # compute the previous noisy sample x_t -> x_t-1\n",
    "                #latents = pipeline.scheduler.step(noise_pred, t, latents, **extra_step_kwargs).prev_sample\n",
    "\n",
    "                # TODO: ddim step customizing with reference_guidance_strength\n",
    "                latents = custum_step_DDIM(pipeline.scheduler, noise_pred, t, latents, reference_latent_X_0, reference_guidance_strength = exp_reference_guidance_decay[i], eta = eta).prev_sample\n",
    "                #call the callback, if provided\n",
    "                if i == len(timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % pipeline.scheduler.order == 0):\n",
    "                    progress_bar.update()\n",
    "                    if callback is not None and i % callback_steps == 0:\n",
    "                        step_idx = i // getattr(pipeline.scheduler, \"order\", 1)\n",
    "                        callback(step_idx, t, latents)\n",
    "\n",
    "\n",
    "        pipeline.maybe_free_model_hooks()\n",
    "\n",
    "        output_latents = latents\n",
    "\n",
    "        latents = 1 / pipeline.vae.config.scaling_factor * latents\n",
    "        mel_spectrogram = pipeline.vae.decode(latents).sample\n",
    "\n",
    "\n",
    "        audio = pipeline.mel_spectrogram_to_waveform(mel_spectrogram)\n",
    "\n",
    "        audio = audio[:, :original_waveform_length]\n",
    "\n",
    "        # 9. Automatic scoring\n",
    "        if num_waveforms_per_prompt > 1 and prompt is not None:\n",
    "            audio = pipeline.score_waveforms(\n",
    "                text=prompt,\n",
    "                audio=audio,\n",
    "                num_waveforms_per_prompt=num_waveforms_per_prompt,\n",
    "                device=device,\n",
    "                dtype=prompt_embeds.dtype,\n",
    "            )\n",
    "\n",
    "        audio = audio.detach().cpu().numpy()\n",
    "\n",
    "        if not return_dict:\n",
    "            return (audio,)\n",
    "\n",
    "        return [output_latents, AudioPipelineOutput(audios=audio)] if output_type == 'latent' else AudioPipelineOutput(audios=audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1733930409783,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "4WmXC6cpnqv6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1733930408294,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "UDicd6b_nqv6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1733930411780,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "ZzzxO0_Cnqv6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def synthesized_instrument_with_reference(instrument_class_prefix, music_type, prompt = \"\", background_music_path = None, latent_path=None, reference_guidance_decay = None, synthesis_strength = 0.7, num_inference_steps=20):\n",
    "    \n",
    "    duration = 10.24\n",
    "    sr = 16000\n",
    "    \n",
    "    prompt_with_prefix = f'[only played by {instrument_class_prefix}]' + prompt\n",
    "\n",
    "    latent_path =  music_type + '_latent_tensor.pt' if latent_path is None else latent_path\n",
    "    music_latent = torch.load(latent_path).to(device)\n",
    "    print(f'latent shape: {music_latent.shape}')\n",
    "\n",
    "    background_music_path = music_type + '_as_reference.wav' if background_music_path is None else background_music_path\n",
    "\n",
    "    original_music, _ = librosa.load(background_music_path, sr=sr, duration=duration)\n",
    "    original_music = audio_volumn_regularization(original_music)\n",
    "\n",
    "    print(f'original_music shape: {original_music.shape}')\n",
    "\n",
    "\n",
    "    synthesized_latent, instrument_added_music = inference_pipe(pipeline,\n",
    "        reference_latent_X_0=music_latent,\n",
    "        reference_guidance_decay = reference_guidance_decay,\n",
    "        eta = 0.1,\n",
    "        prompt = prompt_with_prefix,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        audio_length_in_s=duration,\n",
    "        output_type='latent'\n",
    "    )\n",
    "\n",
    "    instrument_added_music = instrument_added_music.audios[0]\n",
    "    instrument_added_music = audio_volumn_regularization(instrument_added_music)\n",
    "\n",
    "    print(f'instrument_added_music shape: {instrument_added_music.shape}')\n",
    "    only_instrument_file_path = f'[{instrument_class_prefix}]{music_type}_with_guidance_{reference_guidance_decay}.wav'\n",
    "    scipy.io.wavfile.write(only_instrument_file_path, rate=sr, data=instrument_added_music)\n",
    "\n",
    "\n",
    "    mix_with_original(inst= instrument_class_prefix, music_type=music_type, guidance=reference_guidance_decay, weight1=synthesis_strength, background_music_path=background_music_path)\n",
    "\n",
    "    mixed_latent_path = f'[{instrument_class_prefix}]{music_type}_with_guidance_{reference_guidance_decay}_latent_tensor.pt'\n",
    "    mixed_file_path = f'[{instrument_class_prefix}_mixed_with_original]{music_type}_with_guidance_{reference_guidance_decay}.wav'\n",
    "    torch.save(waveform_to_latent(mixed_file_path, pipeline), mixed_latent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12039,
     "status": "ok",
     "timestamp": 1733930015597,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "unPrlqY5nqv6",
    "outputId": "af903d67-2a1f-4737-d6db-84f9d8dc3e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before audio reg(RMS): 0.040106818079948425\n",
      "mel spec length: 1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-85-efb04d67beb4>:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  latent = torch.load(latent_path).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic_music_latent_tensor.pt\n"
     ]
    }
   ],
   "source": [
    "music_type = \"classic_music\"\n",
    "latent_path = make_latent_from_original(music_type)\n",
    "print(latent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8Y-SijUnqv6"
   },
   "source": [
    "# Generate a baseline music(reference) *IF YOU DO NOT HAVE A REFERENCE MUSIC* #\n",
    "If you get your own soundtrack, then this process is not necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "c88601bfdf0b49e08e885d8ea2a9f253",
      "ad36a9edd235401cb5246fd1d0ba7d03",
      "cb63ce40cad443ef94353c5cfb7d525a",
      "0777f1a2e31f45198d2be9700cbe4bf3",
      "6f12f5bc38544fb9bd30caa0d7d6a3cb",
      "88a72054b1e5497bac654e6cf7d2dd3e",
      "d32b66c2f5d04817b235db584f5eece1",
      "20555eb95d384595a5b2dbfb1610c0ae",
      "5749fe4c834e4c4cacb54f7e53b7f711",
      "60d1727ac3a24ed698fe128524597037",
      "83648a03538546949541fc129210f461"
     ]
    },
    "executionInfo": {
     "elapsed": 27722,
     "status": "error",
     "timestamp": 1733923117371,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "9pG2KSUQnqv7",
    "outputId": "59096d67-5968-4290-c328-4722cd760768"
   },
   "outputs": [],
   "source": [
    "prompt = \"soft and harmonic melody based colorful hook part of FUTURE BASS MUSIC\"\n",
    "\n",
    "music_latent = pipeline(\n",
    "    prompt,\n",
    "    num_inference_steps=100,\n",
    "    audio_length_in_s=10.24,\n",
    "    output_type= \"latent\"\n",
    ").audios\n",
    "\n",
    "\n",
    "torch.save(music_latent, music_type + '_latent_tensor.pt')\n",
    "\n",
    "scaled_latent = 1 / pipeline.vae.config.scaling_factor * music_latent\n",
    "mel_spectrogram = pipeline.vae.decode(scaled_latent).sample\n",
    "\n",
    "audio = pipeline.mel_spectrogram_to_waveform(mel_spectrogram)\n",
    "\n",
    "vocoder_upsample_factor = np.prod(pipeline.vocoder.config.upsample_rates) / pipeline.vocoder.config.sampling_rate\n",
    "audio_length_in_s = pipeline.unet.config.sample_size * pipeline.vae_scale_factor * vocoder_upsample_factor\n",
    "original_waveform_length = int(audio_length_in_s * pipeline.vocoder.config.sampling_rate)\n",
    "audio = audio[:, :original_waveform_length]\n",
    "audio = audio.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "scipy.io.wavfile.write(music_type + '_as_reference.wav', rate=16000, data=audio[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdQIJtXbnqv7"
   },
   "source": [
    "#  Synthesize instruments *WHICH IS MAIN PART OF THIS SCRIPT* #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "ada07fc030c94447a42488c53e5fd215",
      "9ad97a389a7249f9818a31ff7c6e5ec4",
      "3b6be85f8dc549659f64b223e2d03d36",
      "8e8e9d7249a84d398192862479ec81ac",
      "c1deec0683c94dc3a4d4610f9053f672",
      "728c59aff02d4268ba20ffd83a70873a",
      "7c4651cac400440e91012838968f4a6c",
      "2bcd94bd6d4f4a788ca1c2cdfad0a225",
      "47b1a824b6b746fba7196d69fdc53d55",
      "4c8836cfe41245278d08367f8511fd25",
      "d19dab0d80c84263897c59f11e75b4a6"
     ]
    },
    "executionInfo": {
     "elapsed": 61715,
     "status": "ok",
     "timestamp": 1733932394300,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "nRTo2vq5nqv7",
    "outputId": "c033c1e0-5db0-4732-fe51-b2b05245a10f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-4fd49106b0f3>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  music_latent = torch.load(latent_path).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent shape: torch.Size([1, 8, 256, 16])\n",
      "before audio reg(RMS): 0.040106818079948425\n",
      "original_music shape: (163840,)\n",
      "device:cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada07fc030c94447a42488c53e5fd215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before audio reg(RMS): 0.10560053586959839\n",
      "instrument_added_music shape: (163840,)\n",
      "before audio reg(RMS): 0.0352860726416111\n",
      "before audio reg(RMS): 0.15000002086162567\n",
      "mel spec length: 1025\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "instrument_class_prefix = 'Guitar' #TODO: change instrument which you want to convert music style to\n",
    "\n",
    "inst_prompt = {\n",
    "'Grand Piano': 'soft, harmonic melody but discrete timbre, colorful and vibrant',\n",
    "'Drum': 'rhythmical, kick and snear included in the sound, various, vibrant',\n",
    "'Guitar': 'fast, anomalous, reckless, frantic, irregular',\n",
    "'Violin': 'continuous, consistent, harmonic, rigorous'\n",
    "}\n",
    "\n",
    "#TODO: 실험 결과\n",
    "# reference_guidance_decay >= 0.943  -> reference를 거의 베끼는 정도\n",
    "# 0.94 > reference_guidance_decay > 0.925  -> 악기에 따라 적절한 정도가 다름(실험 필요)\n",
    "\n",
    "synthesized_instrument_with_reference(instrument_class_prefix, music_type, inst_prompt[instrument_class_prefix],  reference_guidance_decay = 0.927, synthesis_strength=0.15, num_inference_steps=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75FougYZXEmU"
   },
   "source": [
    "# Mixing audios from each instruments #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1733933305556,
     "user": {
      "displayName": "GH X Dable 1",
      "userId": "03325658561426938833"
     },
     "user_tz": -540
    },
    "id": "wultRCbB8K9M",
    "outputId": "b3db7e6e-7994-47e7-c32a-e46e1f17e6cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before audio reg(RMS): 0.10553175956010818\n",
      "before audio reg(RMS): 0.10872796177864075\n",
      "weight distribution: Drum(0.278), Grand Piano(0.278), Guitar(0.444) \n"
     ]
    }
   ],
   "source": [
    "Piano_guidance = 0.93\n",
    "Drum_guidance = 0.93\n",
    "Guitar_guidance = 0.927\n",
    "DtoP = 1.0\n",
    "GtoDP = 0.8\n",
    "mixed_path = mix_two_inst('Drum', 'Grand Piano', music_type, guidance1=Drum_guidance, guidance2=Piano_guidance,  weight1=DtoP)\n",
    "path = mix_with_original(inst= 'Drum_Grand Piano_Guitar', music_type = music_type, weight1=GtoDP, background_music_path=f'[Guitar]{music_type}_with_guidance_{Guitar_guidance}.wav', inst_music_path=mixed_path)\n",
    "print(f'weight distribution: Drum({DtoP/(DtoP+1)/(GtoDP+1):.3f}), Grand Piano({1/(DtoP+1)/(GtoDP+1):.3f}), Guitar({GtoDP/(GtoDP+1):.3f}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hsa9MMsnqv7"
   },
   "outputs": [],
   "source": [
    "# no_guide_instrument_added_music = inference_pipe(pipeline,\n",
    "#     reference_latent_X_0=music_latent,\n",
    "#     #reference_guidance_strength = 1,\n",
    "#     eta = 0.1,\n",
    "#     prompt = prefix_without_prompt,\n",
    "#     num_inference_steps=20,\n",
    "#     audio_length_in_s=10.24,\n",
    "# ).audios\n",
    "\n",
    "# no_guide_save_file_name = '[No_guidance_to_compare]' + instrument_class_prefix + file_name + \".wav\"\n",
    "# scipy.io.wavfile.write(no_guide_save_file_name, rate=16000, data=no_guide_instrument_added_music[0])\n",
    "# scipy.io.wavfile.write('[mixed_with_original]' + save_file_name, rate=16000, data=mix_audios(instrument_added_music[0], audio[0], weight1=0.8, weight2=0.2))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0777f1a2e31f45198d2be9700cbe4bf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60d1727ac3a24ed698fe128524597037",
      "placeholder": "​",
      "style": "IPY_MODEL_83648a03538546949541fc129210f461",
      "value": " 3/100 [00:16&lt;06:30,  4.03s/it]"
     }
    },
    "1dcee4440d0f4842a53332030b5206f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20555eb95d384595a5b2dbfb1610c0ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20f44fdadb3844fe833a9873959d9a4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bcd94bd6d4f4a788ca1c2cdfad0a225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35bcdd1d2e894c63ac5afa4842481835": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6be85f8dc549659f64b223e2d03d36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bcd94bd6d4f4a788ca1c2cdfad0a225",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47b1a824b6b746fba7196d69fdc53d55",
      "value": 25
     }
    },
    "47b1a824b6b746fba7196d69fdc53d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c8836cfe41245278d08367f8511fd25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5749fe4c834e4c4cacb54f7e53b7f711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "60d1727ac3a24ed698fe128524597037": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d9e0c1165f047c4bff2a203e0f3021a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dcee4440d0f4842a53332030b5206f9",
      "placeholder": "​",
      "style": "IPY_MODEL_b4495dea30704bd68c231ca2739e336c",
      "value": " 11/11 [00:04&lt;00:00,  2.46it/s]"
     }
    },
    "6f12f5bc38544fb9bd30caa0d7d6a3cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "728c59aff02d4268ba20ffd83a70873a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7918654a481e4f1ba967c4f8cae3c9d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35bcdd1d2e894c63ac5afa4842481835",
      "max": 11,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e011bdb5b404070b5f6888573a96c4b",
      "value": 11
     }
    },
    "7c4651cac400440e91012838968f4a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ca231a1bc214fb0baa71ad5a2c04692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d30f403e52004129a14d09bcfd1c7b61",
       "IPY_MODEL_7918654a481e4f1ba967c4f8cae3c9d3",
       "IPY_MODEL_6d9e0c1165f047c4bff2a203e0f3021a"
      ],
      "layout": "IPY_MODEL_cbfabbc7000e4b6cb4908312366c892d"
     }
    },
    "7d65956ac0c9404b88c76761653f0269": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e011bdb5b404070b5f6888573a96c4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "83648a03538546949541fc129210f461": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88a72054b1e5497bac654e6cf7d2dd3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e8e9d7249a84d398192862479ec81ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c8836cfe41245278d08367f8511fd25",
      "placeholder": "​",
      "style": "IPY_MODEL_d19dab0d80c84263897c59f11e75b4a6",
      "value": " 25/25 [00:49&lt;00:00,  1.92s/it]"
     }
    },
    "9ad97a389a7249f9818a31ff7c6e5ec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_728c59aff02d4268ba20ffd83a70873a",
      "placeholder": "​",
      "style": "IPY_MODEL_7c4651cac400440e91012838968f4a6c",
      "value": "100%"
     }
    },
    "ad36a9edd235401cb5246fd1d0ba7d03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88a72054b1e5497bac654e6cf7d2dd3e",
      "placeholder": "​",
      "style": "IPY_MODEL_d32b66c2f5d04817b235db584f5eece1",
      "value": "  3%"
     }
    },
    "ada07fc030c94447a42488c53e5fd215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ad97a389a7249f9818a31ff7c6e5ec4",
       "IPY_MODEL_3b6be85f8dc549659f64b223e2d03d36",
       "IPY_MODEL_8e8e9d7249a84d398192862479ec81ac"
      ],
      "layout": "IPY_MODEL_c1deec0683c94dc3a4d4610f9053f672"
     }
    },
    "b4495dea30704bd68c231ca2739e336c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1deec0683c94dc3a4d4610f9053f672": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c88601bfdf0b49e08e885d8ea2a9f253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad36a9edd235401cb5246fd1d0ba7d03",
       "IPY_MODEL_cb63ce40cad443ef94353c5cfb7d525a",
       "IPY_MODEL_0777f1a2e31f45198d2be9700cbe4bf3"
      ],
      "layout": "IPY_MODEL_6f12f5bc38544fb9bd30caa0d7d6a3cb"
     }
    },
    "cb63ce40cad443ef94353c5cfb7d525a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20555eb95d384595a5b2dbfb1610c0ae",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5749fe4c834e4c4cacb54f7e53b7f711",
      "value": 3
     }
    },
    "cbfabbc7000e4b6cb4908312366c892d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d19dab0d80c84263897c59f11e75b4a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d30f403e52004129a14d09bcfd1c7b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d65956ac0c9404b88c76761653f0269",
      "placeholder": "​",
      "style": "IPY_MODEL_20f44fdadb3844fe833a9873959d9a4a",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "d32b66c2f5d04817b235db584f5eece1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
